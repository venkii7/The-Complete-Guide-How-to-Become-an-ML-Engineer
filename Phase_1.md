Build Intuition with 3Blue1Brown
Grant Sanderson is the best math educator on the internet. His neural networks series takes complex concepts and makes them visually intuitive.
Start here. Even if you have some ML background, start here. The visual intuition you'll build is invaluable.

Chapter 1: what is a Neural Network?

Link: 
https://www.youtube.com/watch?v=aircAruvnKk

This video tackles the fundamental question: what is a neural network, really?
It walks through the building blocks—neurons, layers, weights, biases, and activation functions—and shows how they interact.

What makes it especially effective is the visual explanation. The animations turn ideas that are usually abstract into something you can actually see and reason about.

Chapter 2: Gradient descent, how neural networks learn

Link: 
https://www.youtube.com/watch?v=IHZwWFHWa-w

How does a network actually learn?
This video breaks down gradient descent, the fundamental optimization method behind modern deep learning. It shows, step by step, how a model updates its weights to improve performance over time.

One of the most useful parts is the visualization of the loss (cost) function. Once you truly grasp why the objective is to minimize this function—and how gradient descent moves the model in that direction—the rest of machine learning concepts start to click much more naturally.

Chapter 3: What is backpropagation really doing?

Link: 
https://www.youtube.com/watch?v=Ilg3gGewQ5U

This video explains the intuition—what's actually happening when a network learns.


Chapter 4: Backpropagation calculus

Link: 
https://www.youtube.com/watch?v=tIeHLnjs5U8

This video walks through the calculus behind backpropagation—the chain rule in action.

Chapter 5: Large Language Models explained briefly

Link: 
https://www.youtube.com/watch?v=LPZh9BOjkQs

A bridge to modern AI. This video provides a lightweight intro to LLMs—what they are, how they relate to the neural networks you just learned about.
Think of this as a preview. You'll go much deeper with Karpathy later. For now, you're just connecting your foundational knowledge to the systems that power ChatGPT and Claude.

Chapter 6: Transformers, the tech behind LLMs

Link: 
https://www.youtube.com/watch?v=wjZofJX0v4M

The transformer architecture is the breakthrough that made modern AI. This video gives you a visual introduction to how transformers work.

Chapter 7: Attention in transformers, step-by-step

Link: 
https://www.youtube.com/watch?v=eMlx5fFNoYc

Attention is the key mechanism inside transformers. This video breaks it down step by step.

Chapter 8: How might LLMs store facts

Link: 
https://www.youtube.com/watch?v=9-Jl0dxWQs8

This video unpacks the multilayer perceptrons in a transformer—the parts of the network that seem to store factual knowledge.

How do AI images and videos actually work?

Link: 
https://www.youtube.com/watch?v=iv-5mZ_9CPY

This video covering diffusion models—the tech behind image generators like DALL-E, Midjourney, and Stable Diffusion.

